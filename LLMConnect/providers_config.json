{
  "cerebras": {
    "name": "Cerebras",
    "base_url": "https://api.cerebras.ai/v1",
    "endpoint": "chat/completions",
    "api_key_env_var": "CEREBRAS_API_KEY",
    "available_models": [
      "llama-4-scout-17b-16e-instruct",
      "llama3.1-8b",
      "llama-3.3-70b"
    ],
    "default_model": "llama-3.3-70b",
    "default_temperature": 0.7,
    "default_max_tokens": 8000,
    "default_timeout": 30.0
  },
  "groq": {
    "name": "Groq",
    "base_url": "https://api.groq.com/openai/v1",
    "endpoint": "chat/completions",
    "api_key_env_var": "GROQ_API_KEY",
    "available_models": [
      "allam-2-7b",
      "compound-beta",
      "compound-beta-mini",
      "gemma2-9b-it",
      "gemma-7b-it",
      "llama-3.3-70b-versatile",
      "llama-3.3-70b-specdec",
      "deepseek-r1-distill-llama-70b",
      "llama3-groq-70b-8192-tool-use-preview",
      "llama3-groq-8b-8192-tool-use-preview",
      "llama-3.1-70b-versatile",
      "llama-3.1-8b-instant",
      "llama-3.2-1b-preview",
      "llama-3.2-3b-preview",
      "llama-3.2-11b-vision-preview",
      "llama-3.2-90b-vision-preview",
      "llama-guard-3-8b",
      "llama3-70b-8192",
      "llama3-8b-8192",
      "mixtral-8x7b-32768"
    ],
    "default_model": "llama-3.3-70b-versatile",
    "default_temperature": 0.7,
    "default_max_tokens": 8000,
    "default_timeout": 30.0
  },
  "openrouter": {
    "name": "OpenRouter",
    "base_url": "https://openrouter.ai/api/v1",
    "endpoint": "chat/completions",
    "api_key_env_var": "OPENROUTER_API_KEY",
    "available_models": [
      "google/gemini-2.5-flash-image-preview:free",
      "deepseek/deepseek-chat-v3.1:free",
      "openai/gpt-oss-120b:free",
      "openai/gpt-oss-20b:free",
      "z-ai/glm-4.5-air:free",
      "qwen/qwen3-coder:free",
      "moonshotai/kimi-k2:free",
      "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
      "google/gemma-3n-e2b-it:free",
      "tencent/hunyuan-a13b-instruct:free",
      "tngtech/deepseek-r1t2-chimera:free",
      "mistralai/mistral-small-3.2-24b-instruct:free",
      "moonshotai/kimi-dev-72b:free",
      "deepseek/deepseek-r1-0528-qwen3-8b:free",
      "deepseek/deepseek-r1-0528:free",
      "mistralai/devstral-small-2505:free",
      "google/gemma-3n-e4b-it:free",
      "meta-llama/llama-3.3-8b-instruct:free",
      "qwen/qwen3-4b:free",
      "qwen/qwen3-30b-a3b:free",
      "qwen/qwen3-8b:free",
      "qwen/qwen3-14b:free",
      "qwen/qwen3-235b-a22b:free",
      "tngtech/deepseek-r1t-chimera:free",
      "microsoft/mai-ds-r1:free",
      "shisa-ai/shisa-v2-llama3.3-70b:free",
      "arliai/qwq-32b-arliai-rpr-v1:free",
      "agentica-org/deepcoder-14b-preview:free",
      "moonshotai/kimi-vl-a3b-thinking:free",
      "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
      "meta-llama/llama-4-maverick:free",
      "meta-llama/llama-4-scout:free",
      "qwen/qwen2.5-vl-32b-instruct:free",
      "deepseek/deepseek-chat-v3-0324:free",
      "mistralai/mistral-small-3.1-24b-instruct:free",
      "google/gemma-3-4b-it:free",
      "google/gemma-3-12b-it:free",
      "rekaai/reka-flash-3:free",
      "google/gemma-3-27b-it:free",
      "qwen/qwq-32b:free",
      "nousresearch/deephermes-3-llama-3-8b-preview:free",
      "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
      "cognitivecomputations/dolphin3.0-mistral-24b:free",
      "qwen/qwen2.5-vl-72b-instruct:free",
      "mistralai/mistral-small-24b-instruct-2501:free",
      "deepseek/deepseek-r1-distill-qwen-14b:free",
      "deepseek/deepseek-r1-distill-llama-70b:free",
      "deepseek/deepseek-r1:free",
      "google/gemini-2.0-flash-exp:free",
      "meta-llama/llama-3.3-70b-instruct:free",
      "qwen/qwen-2.5-coder-32b-instruct:free",
      "meta-llama/llama-3.2-3b-instruct:free",
      "qwen/qwen-2.5-72b-instruct:free",
      "meta-llama/llama-3.1-405b-instruct:free",
      "mistralai/mistral-nemo:free",
      "google/gemma-2-9b-it:free",
      "mistralai/mistral-7b-instruct:free"
    ],
    "default_model": "tngtech/deepseek-r1t-chimera:free",
    "default_temperature": 0.7,
    "default_max_tokens": 8000,
    "default_timeout": 30.0
  }
}